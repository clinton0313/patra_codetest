# Thoughts, Issues, Extensions

I had a lot of fun doing this and chose to fine-tune BERT to make a classifier. Although, my computer doesnâ€™t have a GPU and I knew that it would be a bit slow, I thought that this would be a great way to jump-start into understanding how to work with BERT. One of the other main issues I ran into aside from training time was I actually spent quite a bit of time understanding how to coerce the data from the CSV form to a TensorFlow dataset that BERT liked. 

From a coding perspective, I left all the code in one file for ease of reading, but if this were a longer term project, I would definitely separate the functions, classes, EDA, model training, etc into separate files. 

I had a few thoughts about the exercise. Firstly, if this were an actual project, I would start by talking to the business team and understand the costs and benefits of missing a negative review (unhappy customer) vs mis-classifying a positive review as negative (slightly more work for our customer service agents). On this note, I had a bit of time to experiment working with class weights and the threshold for prediction trying to prioritize not missing negative reviews. If I had more time I would want to fine tune these to align with business requirements by working with the ROC/AUC curve. 

I used a minimal architecture for reasons of time, but realistically, I would want to explore stacking either a CNN model or a LSTM model on top of BERT so that the classification decision takes advantage of context better (especially with the pooling of the convolutions). Another way to improve this model would be to use more than 2 or 3 epochs of training as well as experiment with the learning rate. Here, a learning rate scheduler should be used and proper use of checkpoints for the model and early stopping criterion would make this larger training regime a lot more feasible. Nonetheless, I assume you are more interested in my code and ideas than how long I watched the model train for. 

Another obvious limitation is the small number of negative reviews (87) and once split to a training and test set even smaller. More epochs would certainly help pass this information through the gradients. Another tactic could be to leverage transfer learning. There are many well labelled sentiment datasets such as: https://www.kaggle.com/datasets/arbazkhan971/product-sentiment-analysis where the model could be largely pre-trained and then fine-tuned on in-house data if data is lacking. 

Another important thing would be to get some level of uncertainty to identify the reviews that could use a second look by a human. The softmax score is known to be inaccurate and definitely crude. Good ways for neural networks would be either using MCDropout (known to understate but quickly and easily implementable) or Enembling (a bit more expensive training, but also should improve predictions). 

A future future extension that would be interesting and potentially helpful would be to work with a seq2seq model that could already suggest replies to the negative reviews. That would be something to explore after getting a working customer review classifier. 